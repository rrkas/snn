{
    "references/11Vol98No24.pdf": {
        "variants of eSNN": {
            "Hybridization": "covers studies which present eSNN as a hybrid model with different algorithms",
            "Modifications": "studies that modified eSNN architecture to solve some real-world tasks",
            "Multi-objective": "studies which involve eSNN for multi-objective optimization",
            "Dynamic": "studies about Dynamic eSNN",
            "Integration": "studies that used eSNN to propose integrated models"
        },
        "ANN": [
            "motivated by the erection and human brain purpose",
            "used as an influential computational mechanism to unravel complex function estimation, classification problems, and pattern recognition",
            "converted the in-practice standard means to execute supervised, unsupervised, and reinforcement learning tasks",
            "important developments have been made through algorithmic development"
        ],
        "Need of SNN": [
            "Investigations of the cortical pyramidal neurons revealed discrete spikes timing as a mode of encrypting information, which is very imperative in neural networks",
            "considerably close to the human brain structure due to their spiking nature",
            "increases the level of biological pragmatism by using individual spikes and plays a key role in biological information processing",
            "competent to process a considerable number of facts using comparatively few spikes",
            "allow integration of spatial-temporal data for communication and computation as actual neurons do"
        ],
        "Conversion of real-world data": {
            "rate order encoding": "amplitudes are transformed into the (instantaneous) spiking amount of neurons",
            "time encoding": "amplitudes are encoded into spike timings",
            "population coding": "amplitudes are programmed into the direct shooting rate"
        },
        "eSNN": [
            "one- pass, on-line learning technique, where new data is learned incrementally, including the merging/aggregating production neurons",
            "Built on the ECOS methodology",
            "originally designed as a visual pattern recognition scheme",
            "can learn fast and it studies a new pattern that comes from the incoming data in one pass-mode that will form a new network without retraining",
            "widely applied to solve classification issue, prediction problem and pattern recognition",
            "To organize real-valued facts, each data model i.e. vectors of real-valued elements is plotted into a sequence of spikes using a convinced neural encoding procedure",
            "enhances the importance of the direction in which input spikes reach, so making the eSNN appropriate for a variety of applications",
            "self-evolutionary in terms of success, behavior, connected knowledge representation, and global fault tolerance"
        ],
        "core parameters": [
            "modulation factor (Mod)",
            "threshold factor  (C)",
            "similarity value  (Sim)"
        ],
        "Learning of eSNN" : [
            "the propagate single sample from class K, into the first and second layer",
            "create a neuron at layer three for sample propagated at preceding layers and weight training",
            "similarity factor is calculated between the newly created neurons and the neurons that are already presented in the respective class. To calculate similarity inverse of Euclidean Distance(between connection weights of neurons) is used.",
            "the newly created neuron joins any of the class based on calculated similarity value (if it is greater than the selected threshold value)"
        ],
        "VARIANTS OF eSNN": {
            "eSNN-FA (Firefly Algorithm)": [
                "Nature-inspired meta-heuristic algorithm, for parameter optimization of the eSNN model",
                "FA is used to determine the optimum value of eSNN parameter which are a mod factor, sim factor, and C factor (threshold)",
                "parameters of eSNN are optimized using FA to get optimal performance",
                "The integration of eSNN-FA is conducted using the well-known Wrapper method",
                "The wrapper method takes the classifier and melds with an optimization algorithm",
                "a set of random values is used to initialize all the candidates",
                "candidates interact with each other founded on classification precision",
                "As an example, all contributing samples will be programmed into spikes and pass over the eSNN model to discover the current suitability",
                "The FA-Best is assigned with the best classification accuracy hold by the candidates",
                "If the FA candidates encounter a better result compared to the FA-Best, the newly created FA-Best will replace the FA-Best",
                "The iteration will be repeated until the termination criterion is reached."
            ],
            "Multi-objective Optimization (MOO) of eSNN": [
                "enhances the process of optimization",
                "The progression of systematically adjusting objectives at a similar time is acknowledged as vector optimization or MOO",
                "Synchronized optimization is the need for various real-life optimization problems with two or more objective functions",
                "In this hybrid process, k-means improve eSNN knowledge founded on multi-objective D.E by categorizing given information through a certain number of bunches (k clusters).",
                "Three main parameters that influence the segregation outcome of eSNN are optimized in this work and are known as the Mod(modulation factor), C(threshold), and Sim(similarity factor).",
                "The proposed model lifts the adaptability of eSNN in giving a better solution that can be used to conquer k-means disadvantages."
            ],
            "Dynamic eSNN": [
                "A fully connected neural network"
            ]
        }
    }
}